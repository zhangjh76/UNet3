UNet：UNet主要是将解码层（下采样层）与编码层（上采样层）中同层之间进行连接。U型结构的低层主要是获取细粒度的细节特征（捕获丰富的空间信息），高层主要是获取粗粒度的语义特征（提现位置信息），所以UNet的这种仅有同层之间的连接，使得他的上下层连接时存在信息代沟现象。

UNet++:UNet++由UNet改编而来，具有嵌套、稠密的跳跃连接，一定程度缓解了UNet层次间的代沟问题，性能也相对提升了不少。

UNet3+：
（1）UNet3+提出全尺度跳跃连接，此连接将来自不同尺度特征图的低级细节与高级语义相结合，最大程度使用全尺度的特征图，提高分割精度。

（2）深监督：深度监督从全尺度聚合特征图中学习层次代表。

（3）通过减少网络参数来提升计算效益。

（4）提出混合损失函数以增强器官边缘。

（5）设计了一个分类引导模型以减少在无器官图像中的过度分割现象。


UNet3+是具有编码器（Encoder）-解码器（Decoder）结构的深度学习网络之一。
编码Encoder：
编码部分：首先将输入的图像经过两次3*3卷积，每次卷积都紧跟着BatchNorm2d、ReLU。然后进行最大池操作，即 stride=2的2*2卷积。值得注意的是最下面一层即第五层卷积后不再进行下采样（最大池操作）。
解释 3*3卷积、BatchNorm2d、ReLU、最大池操作：
1）3*3卷积
卷积操作影响特征通道，下采样（本模型下采样用的maxpool）影响分辨率。
2）BatchNorm2d
此处是为了将3*3卷积后的特征图进行数据归一化处理，防止后续的ReLU激活函数操作时，出现由于特征图数据过大，出现网络性能不稳定的问题。
3）ReLU
激活函数。
3）最大池化
maxpool使用的是2*2的卷积核，用来提取特征，使特征图分辨率缩小1倍。

解码Decoder：
每个解码的实现机制是一样的，论文中是以Decoder3为例讲解的，我们也以Decoder3为例详细讲解，同时也介绍其它层的具体实现过程。

1）跳跃连接  
Unet3+以全尺度连接为突出创新点，他的全尺度连接是在解码层实现的，具体来说就是该网络的每个解码层的特征图是通过5个尺度的特征图通过一定操作组成的。以Decoder3 为例详细介绍：
Decoder3的特征图是由来源于编码层中比它低层的Encoder1、Encoder2，和它同层的Encoder3，以及解码层中比它高层的Decoder4、Decoder5的特征图分别通过一些操作后构成的。那分别是做了哪些操作呢？
Encoder1：将特征图进行最大池无重叠操作，即stride=4的操作，记为maxpooling(4)，然后进行64特征通道的3*3卷积，以及ReLU，总结就是maxpooling(4)、64特征通道、3*3conv、ReLU。
Encoder2：maxpooling(2)，64, 3*3Conv，ReLU。
Encoder3：64， 3*3conv， ReLU. （因为是同层，他们的特征通道特征图分辨率是相同的，不需要最大池提取特征。）
Decoder4：首先进行双线性上采样操作，然后特征图64的3*3卷积，ReLU操作。总计即 bilinear upsample(2), 64, 3*3conv, ReLU。
Decoder5：bilinear upsample(4), 64, 3*3conv, ReLU。
即在Encoder中，比Decoder3低的encoder中做分辨率缩小操作（maxpool）；在decoder中，比decoder3高的decoder做分辨率变大操作（双线性上采样 bilinear upsample）。具体的操作倍数由层次决定。
接下来从下往上简要介绍其他解码层的情况。
Decoder5: = Encoder5，故不做任何处理。
Decoder4: 
         encoder1: maxpooling(8), 64, 3*3conv, ReLU.
         encoder2: maxpooling(4), 64, 3*3cong, ReLU.
         encoder3: maxpooling(2), 64, 3*3cong, ReLU.
         encoder4: 64, 3*3cong, ReLU.
         decoder5: bilinear upsample(2), 64, 3*3conv, ReLU.        
Decoder2:
         encoder1: maxpooling(2), 64, 3*3conv, ReLU.
         encoder2: 64, 3*3cong, ReLU.
         Decoder3: bilinear umsample(2), 64, 3*3conv, ReLU.
         Decoder4: bilinear umsample(4), 64, 3*3conv, ReLU.
         Decoder5: bilinear umsample(8), 64, 3*3conv, ReLU.
Decoder1: 
         encoder1: 64, 3*3conv, ReLU.
         Decoder2: bilinear umsample(2), 64, 3*3conv, ReLU.
         Decoder3: bilinear umsample(4), 64, 3*3conv, ReLU.
         Decoder4: bilinear umsample(8), 64, 3*3conv, ReLU.
         Decoder5: bilinear umsample(16), 64, 3*3conv, ReLU.

2）分类引导模块 classification-guided module(CGM)
从拥有最丰富语义信息的Encoder5中进行一系列操作，最后分割结果能进一步指导解码层中每一层的输出。
对Encoder5的一系列操作包括dropout，1*1卷积，自适应最大池AdaptiveMaxPool, Sigmoid操作，该一系列操作后得到一个2维张量；通过一个argmax函数，2维tensor转化为 {0,1} 中的一个单一输出；在每一个解码层中，将深监督阶段内bilinear up-sampling操作后的分割结果与分割结果0/1相乘。最后实现了将每层中的分割结果进行了分类。

3）特征聚合机制
为了将浅层空间信息与深层语义信息精密合并，提出了特征聚合机制，该机制是将跳跃连接组成的320通道的特征图进一步聚合。具体操作是：将跳跃连接后的320个通道的特征图进行3*3卷积操作，BN数据归一化处理，ReLU激活。

4）深监督
为了了解全尺度聚合特征图的阶层表达，在UNet3+上提出了全尺度深监督，在每一个解码层生成一个受ground truth监督的侧边输出。该步骤的操作包括：3*3conv，bilinear up-sampling, sigmoid。
深监督的具体操作是：将每个解码层的经过特征聚合机制生成的特征图的最后一层输入3*3卷积层内，之后伴随着一个双线性上采样bilinear up-sampling。然后将上采样后得到的分割结果与分类模块的结果0/1相乘；将相乘后的结果经过sigmoid处理，得到的结果即深监督的输出结果。然后将深监督结果输入损失函数。

5)混合损失函数